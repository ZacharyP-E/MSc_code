{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1da05d44",
   "metadata": {},
   "source": [
    "# External Data Download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fba4987",
   "metadata": {},
   "source": [
    "This notebook acts as the first step in the data analysis pipeline. It takes UPRN (Unique Property Reference Number) information provided by WMFS incident reports and utilises it to download property-specific data. Additionally, it fetches weather data corresponding to the time of each incident. The aim is to enrich the incident dataset with additional contextual data for subsequent analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42daf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required packages\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4276236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_info = pd.read_csv('../../data/final/inc_info.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecd46ab",
   "metadata": {},
   "source": [
    "## UPRN Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a415c435",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = '*********'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f1702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "uprns = list(inc_info['uprn'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406e000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in any existing uprn data (to no repeat requests).\n",
    "uprn_master = pd.read_csv('../../data/final/uprn/uprn_master.csv')\n",
    "uprn_master = uprn_master.drop(labels=\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e118f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting a list for uprns resulting in errors, so they are not repeated.\n",
    "error_uprns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cc0cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in uprns[:]:\n",
    "    if uprn_master[uprn_master['uprn'] == i].shape[0] == 0 and i not in error_uprns:\n",
    "        print(\"Gathering: \" + str(i))\n",
    "        \n",
    "        try:\n",
    "            # Request\n",
    "            temp_response = requests.get('https://api.propertydata.co.uk/uprn?key=' + api_key + '&uprn=' + str(i))\n",
    "            temp_response.raise_for_status()  # Raise an exception for 4xx and 5xx status codes\n",
    "\n",
    "\n",
    "            # Data to DataFrame\n",
    "            temp_uprn_data = pd.DataFrame(temp_response.json())[['data']].T.reset_index()\n",
    "\n",
    "\n",
    "            # Add UPRN to DataFrame\n",
    "            temp_uprn_data['uprn'] = int(pd.DataFrame(temp_response.json())[['uprn']].iloc[0])\n",
    "\n",
    "            # Concat to end of master\n",
    "\n",
    "            uprn_master = pd.concat([uprn_master, temp_uprn_data])\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(\"Error processing UPRN: \" + str(i))\n",
    "            print(\"Exception: \" + str(e))\n",
    "            error_uprns.append(i)  # Add the UPRN to the list of errors\n",
    "            \n",
    "        \n",
    "        # Introduce a 2-second delay before the next iteration\n",
    "        time.sleep(2)\n",
    "        \n",
    "\n",
    "    else:\n",
    "        print(\"Already gathered: \" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5d0059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting UPRN data to csv file\n",
    "uprn_master.to_csv('../data/final/uprn/uprn_master.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0c7fb3",
   "metadata": {},
   "source": [
    "## Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0489d401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the incident info data with uprn data and dropping NA values in the internal area column.\n",
    "df = inc_info.merge(uprn_master, on=\"uprn\", how=\"inner\")\n",
    "df = df.dropna(subset=[\"internalArea\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b624df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to transform coordinates from EPSG:27700 to EPSG:4326\n",
    "def transform_coordinates(row):\n",
    "    transformer = Transformer.from_crs(\"EPSG:27700\", \"EPSG:4326\")\n",
    "    lon, lat = transformer.transform(row['location_x'], row['location_y'])\n",
    "    return pd.Series({'longitude': lon, 'latitude': lat})\n",
    "\n",
    "\n",
    "# Apply the transformation to the DataFrame\n",
    "df[['longitude', 'latitude']] = df.apply(transform_coordinates, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e36f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'call_time' column to datetime format\n",
    "df['call_time'] = pd.to_datetime(df['call_time'])\n",
    "\n",
    "# Create an empty master DataFrame to store the extracted information\n",
    "master_df = pd.DataFrame(columns=['vis_inc_num', 'date', 'mean_temperature', 'precipitation_sum', 'windspeed'])\n",
    "\n",
    "# Loop through each incident in the DataFrame\n",
    "for index, incident in df.iterrows():\n",
    "    # Get the date of the incident\n",
    "    date = incident['call_time'].date()\n",
    "    \n",
    "    # Fetch the API response for this incident\n",
    "    api_response = requests.get(\"https://archive-api.open-meteo.com/v1/archive?latitude={}&longitude={}&start_date={}&end_date={}&daily=temperature_2m_mean,precipitation_sum,windspeed_10m_max&timezone=GMT\".format(incident['latitude'], incident['longitude'], date - pd.Timedelta(days=7), date))\n",
    "    \n",
    "    # Parse the API response into a DataFrame\n",
    "    api_response_df = pd.DataFrame(api_response.json()['daily'])\n",
    "    \n",
    "    # Extract the mean of the \"temperature_2m_mean\" column\n",
    "    mean_temperature = api_response_df['temperature_2m_mean'].mean()\n",
    "\n",
    "    # Extract the sum of the \"precipitation_sum\" column\n",
    "    precipitation_sum = api_response_df['precipitation_sum'].sum()\n",
    "\n",
    "    # Extract the windspeed for the last day (day of incident)\n",
    "    windspeed = api_response_df.iloc[-1]['windspeed_10m_max']\n",
    "\n",
    "    # Create a new row with the extracted information\n",
    "    new_row = pd.DataFrame([[incident['vis_inc_num'], date, mean_temperature, precipitation_sum, windspeed]], columns=master_df.columns)\n",
    "\n",
    "    # Append the new row to the master DataFrame\n",
    "    master_df = master_df.append(new_row, ignore_index=True)\n",
    "    \n",
    "    print(\"Done: \" + str(index))\n",
    "\n",
    "# Now master_df contains the extracted information for all incidents, associated with the 'vis_inc_num' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b6e1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Duplicates from the data\n",
    "master_df = master_df.drop_duplicates()\n",
    "\n",
    "# Exporting the weather data to csv file. \n",
    "master_df.to_csv(\"../data/final/weather.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
